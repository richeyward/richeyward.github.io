---
title: "Korelogic - Crack Me If You Can - 2010 - Part 1"
subtitle: ""
url: "/cmiyc/2010-p1"
date: "2023-05-31"
lastmod: 2023-05-31
draft: false
tags:
    - korelogic
    - cmiyc
categories:
    - CTF
---

Korelogic's *"Catch Me If You Can"* 2010 challenge was a password cracking contest designed especially for DEFCON 18 in 2010. The original contest took place over 48 hours. The following is taken from the original contest page.

## Challenge Details

### Scenario
As a part of an authorized penetration test of a large corporate network, you have captured a large number of password hashes. The hashes are from Active Directory, UNIX systems, LDAP servers, routers, etc. As part of your analysis, your client has asked for password complexity statistics, what their users are doing right and/or wrong related to generating passwords, and identification of weak passwords. You only have 48 hours to complete this effort.

### Logistics
On Thursday, at 11:59 PM DEFCON time (US/Pacific), KoreLogic will release a file containing 53,000+ password hashes. The file will contain passwords of varying types (such as SHA, SSHA, MD5, DES, Lanman, NTLM, etc.) and will range from being "easy" to extremely difficult to crack. The password file is not simply 53,000 randomly generated passwords which would favor the person or group with the most GPU/CPU bruteforcing horsepower. Instead, the password file contains passwords based on what we believe are challenging patterns. Passwords will be of varying lengths, patterns, and complexity. Creative password cracking techniques, rules, dictionaries, and tools will be needed. The teams who are smart about the methods they use (i.e., teams who can crack more, with less work) will most likely be the most successful.

The goal of the contest is twofold:
-   To crack as many passwords as possible.
-   To crack all the "administrative/root" passwords.

The contest will be judged on a point system where:
-   Each user password cracked earns 1 point.
-   Each administrative password cracked earns 100 points.

### Challenge File
The file can be located [here](https://contest-2010.korelogic.com/defcon_contest_hashes.txt)


## Initial Analysis

The file actually contains 54680 rows of different password hashes and types. The logistics above detail usage of rules and dictionaries to be sucessful (and we will make heavy use of them), but as we have zero knowledge of what was used, the first step will be to brute force our way for a bit. As there are different hash types used, it would be common sense to attempt to crack ones with the lowest intensity.  The goal now lies in finding a way to identify the different hash types.  As this will only need to be done once, a quick Python script is sufficient.


```python
#!/usr/bin/env python3

import os
import re
import sys

from collections import Counter

patterns = [
    ["Raw-SHA1",    "^[a-z_0-9]+:\{SHA\}.+"],
    ["SSHA",   "^[a-z_0-9]+:\{SSHA}.+"],
    ["NTLM" ,     "^[a-z_0-9]+:[0-9]+:[0-9A-F]{32}:[0-9A-F]{32}:::$"],
    ["md5crypt",  "^[a-z_0-9]+:\$1\$.{31}:[0-9]+:"],
    ["descrypt",  "^[a-z_0-9]+:.{13}:[0-9]+:.+"],
    ["bcrypt",    "^[a-z_0-9]+:\$2a\$05\$.{53}:123:[0-9]+:::::$"],
]

class HD(object):
    def __init__(self):
        if len(sys.argv) != 2:
            print("Usage: hash_identifier.py <hashfile>")
            sys.exit(0)

        self.hashes = []
        with open(sys.argv[1]) as f:
            for h in f.read().splitlines():
                self.check_regexs(h)
            self.print_data()

    def check_regexs(self, h):
        for p in patterns:
            if re.match(p[1], h):
                # print(p[0], h)
                self.hashes.append(p[0])
                return
        print("Unknown hash: %s" % h)
        self.hashes.append("Unknown")

    def print_data(self):
        c = Counter(self.hashes)
        for i in c.most_common():
            print(i)


if __name__ == "__main__":
    HD()
```

The hash regexes were built over long trial and error. I managed to detect all of them except one which I will return to at a later date. Next, I correlated the hashes with JTR's internal benchmarking using `john --test`. Even though I intend to use the GPU to crack the passwords, the benchmark could only be used on CPU algorithms, but the outcome should be the same. Note that benchmark speeds can differ greatly on different systems.

__(Note: Speed is a WIP)__

| Type     | Count | Speed       |
| -------- | ----- | ----------- |
| NTLM     | 30821 | 8857M c/s   | 
| SSHA     | 10582 | 3024M c/s   |
| DESCrypt | 7155  | 54329K c/s  |
| MD5Crypt | 4716  | 449280 c/s  |
| Unknown  | 1000  | ?           |
| SHA1     | 326   | 28765K c/s  |
| bcrypt   | 80    | 16110 c/s   |

Given that NTLM hashes are very quick to crack, and are the most abundant, this would be an excellent place to start.


## NTLM Brute Forcing

The [NTLM](https://en.wikipedia.org/wiki/NTLM) hash protocol is commonly found on Windows systems and look like this:
```
aakuchie:1000:AAD3B435B51404EEAAD3B435B51404EE:615A08798F38159612CC61DF8F535C9B:::
aalar:1000:AAD3B435B51404EEAAD3B435B51404EE:87E8D721900F434850972414B5F9E47A:::
aalday:1000:AAD3B435B51404EEAAD3B435B51404EE:EB8A863965D0A8CB06BC1D54BC580F7B:::
aaldecoa:1000:AAD3B435B51404EEAAD3B435B51404EE:1C9EF0836F59E5FE115F950D16C4E38A:::
aalderete:1000:AAD3B435B51404EEAAD3B435B51404EE:85E646EF3ED151F1692093FE8060CE45:::
aaldrege:1000:AAD3B435B51404EEAAD3B435B51404EE:ADEE66A3B1E504CB3100AD0D3E02C425:::
aalegar:1000:AAD3B435B51404EEAAD3B435B51404EE:331AA8A8D6CFE7E33AA4BD657D1EA53A:::
aalejos:1000:AAD3B435B51404EEAAD3B435B51404EE:1F08F8CDDB733F797CC92FA63866DFE0:::
aalekna:1000:AAD3B435B51404EEAAD3B435B51404EE:789384432768FCED08E4F87BADDE8065:::
aalgire:1000:64F6199C49B2788F171D3CAF4E8CE415:5B2506ED7494D88EA750F6642FAA6D82:::
aali:1000:EA89F2FF6A21442893E28745B8BF4BA6:DA86E691E8C94CB3211F6701923CAFA3:::
aallaire:1000:AAD3B435B51404EEAAD3B435B51404EE:F1B2C0246F6606259319CD3E5969047F:::
aallamong:1000:AAD3B435B51404EEAAD3B435B51404EE:CBF0AA18169FB2C04AF3A6BDB399C899:::
```

The structure for this is unique, in that it actually contains two separate types of hashes, the NT hash and the LM hash.  `[username:uid:LM Hash:NT Hash]`.  While the NT hash is relatively easy to crack, all permutations of the LM hash can be cracked in minutes and is incredibly weak.   

### The LM hash

The [Lan Manager](https://en.wikipedia.org/wiki/LAN_Manager) (LM) hash has been around since the early 90s and was built around a time when password hash complexity was not a big concern. It is however fraught with weaknesses. Some highlights are:
- The maximum length of the password can be 14 characters chosen out of a pool of 95 ASCII characters.
- The password is converted to uppercase, meaning that `password` and `PaSsWoRd` have the same hash and are considered identical. This also means that the combination of characters is reduced from 95 ASCII chars to 69 characters.
- The password is padded to 14 character length with null bytes then it is split in two before being hashed. This means that in reality the LM hash is two separate hashes of 65^7 characters.

Do demonstrate this, here are a few example LM hashes. I have split them in two 

```
1. password123     E52CAC67419A9A22 664345140A852F61
2. password456     E52CAC67419A9A22 285AEC685A17B6FD  # same first hash as 1 (passwor)
3. codeword123     28DA9078E6B48B29 664345140A852F61  # same second hash as 2 (d123)
4. PASSWORD123     E52CAC67419A9A22 664345140A852F61  # same hash as 1 (case insensitive)
5. testingtesting  2D5545077D7B7D2A 2D5545077D7B7D2A  # first and second hashes match (testing)
```

These weaknesses can be exploited in order to figure out the password.  In later years, the NT hash algorithm was introduced to replace LM, however for legacy reasons the LM hash was stored stored alongside the NT hash. Once the LM hash was cracked, it was trivial to also crack the NT hash as you had an uppercase version of it supplied by the LM hash.

Over time the LM hash was disabled as it was incredibly weak by more modern standards and was replaced by the value `AAD3B435B51404EE` which is an empty string hashed.  In the sample data above, it can be seen twice in the LM hash, showing that this is not prone to LM hash cracking however some do have LM hashes, so let's start there.


### Cracking LM

Out of the 30821 NTLM hashes in the file, 2558 have LM hashes attached.  The hash identifier script already extracted the NTLM hashes into `hashes/NTLM.txt` so I will just carve out the LM hashes into a new file. This is purely optional, but I wanted to be clean.  Time to start john.

To brute force using john, you have to supply the hash file and optionally the format. This is useful in this instance for two reasons, one is that it will try to crack the NT hashes first, and we want it to crack the LM hashes, secondly is the fact that if set up correctly, john can use a GPU for password cracking which is **much** faster. To enable this, the '-opencl' flag is appended to the format.  Also john uses an inbuilt password storage file (called a pot), but as we are working from scratch, I will just use a local one....

For brute forcing, we will be enabling a *mask* which tells john how to permutate the password. The `?a` flag means to try any alphanumeric character. This will only try all passwords of length 1 as the mask is a length of 1.

```
#             <format>        <pot file>  <password mask>    <hash file>
john --format=LM-opencl --pot=kl2010.pot  --mask="?a"        hashes/LM.txt
```

It is also possible to use the same mask for more than one character when using the `--min-length` and `--max-length` flags.  For an unknown reason, the lowest that it could be set to was 2, so the following was executed.

```
john --format=LM-opencl --pot=kl2010.pot --min-length=2 --max-length=7 --mask="?a" hashes/LM.txt
```

Cracking of all LM hashes took me just 18 minutes.  Checking the status shows that all values were found.

```
john --pot=kl2010.pot --format=LM hashes/LM.txt --show

<snip>

4433 password hashes cracked, 0 left
```

Now that we have all the segments of the LM hashes cracked, we can now replay them for cracking the NT hashes.  To do this, we use the loopback feature.

```
john --format=NT-opencl --pot=kl2010.pot --loopback=kl2010.pot hashes/LM.txt

john --pot=kl2010.pot --format=NT hashes/LM.txt --show
2557 password hashes cracked, 1 left
```

All but one of the NT hashes with an LM hash are cracked.  The outlier is likely a password which is longer than 14 characters long. While the LM hashes for it are found, the remaining characters are not, and as a result the NT hash is not cracked.

### NT Brute Forcing

Much like what we did with the LM hashes, we will also perform a brute force of NT hashes up to 7 characters. 

```
john --format=NT-opencl --pot=kl2010.pot --mask="?a" --min-length=1 --max-length=7 hashes/NTLM.txt

john --pot=kl2010.pot --format=NT hashes/NTLM.txt --show | grep cracked
5711 password hashes cracked, 25110 left

```

The cracking of 1-6 characters was only a few minutes but the 7 character passwords made the whole process around 4 hours. I am okay in cracking for a few hours but the whole point of the exercise is to be smarter than just blindly bruting.  Now that we have a pool of passwords at our disposal, we can start to perform some analytics to identify dictionaries and rules that we can create.


## Statistical Analysis of Cracked Hashes

The next phase of analysis can begin, which will be a continual loop ad infinitum.  At the start of this process, we have 5711 brute forced passwords which will we now call 'bruted'.  We want to figure out what dictionary wordlists and rules were used to create the bruted words. Once we make a decision, a run of the wordlist and rule (called a solve) will be ran. The solves should find new passwords and ones in the bruted list will be removed. This process will repeat until there is diminishing returns. To recap, the process is as follows:

- Remove solved passwords from bruted pile
- Analyze remaining bruted passwords for patterns
- Create new wordlists and rules from analysis
- Run new solves
- Repeat

## Conclusion

Now that we have sufficient passwords and a strategy, it is time to move to the next phase, Analytics

(Coming Soon)